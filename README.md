# Project Overview

This repository implements a data pipeline for generating marketing insights and reports. The project is organized into several modules, each with a distinct role in the pipeline—from loading and transforming raw data to validating, aggregating, and visualizing the final results. Below is a summary of the main folders and modules:

## charts/

Contains the charts generated by the pipeline. These visual outputs (e.g., line graphs, bar charts, scatter plots) provide actionable marketing insights that can be used by Data Science Team.

## config/

Holds YAML configuration files that define the settings for the pipeline. This includes paths to data sources, transformation rules, validation criteria, and output locations.

## data/

-   **raw/**: Stores the raw data files.
-   **processed/**: Contains processed data files produced by the pipeline.
    -   **final_dataset/**: Holds the final, merged dataset after all cleaning and transformation steps.
    -   **reports/**: Contains required generated report files (CSV).

## logs/

Stores JSON log files generated every time the pipeline runs. These logs record important metadata (last processed dates of channel sources) used in the pipeline execution.

## src/

This folder contains the source code of the application and is divided into several modules:

-   **aggregation/**: Aggregates the final processed data into summary reports.
-   **data_loaders/**: Contains scripts for loading data from various sources (e.g., CSV files).
-   **setup/**: Holds scripts that install and manage the required packages for the project.
-   **transformation/**: Contains code for transforming source data, including cleaning, renaming columns, and changing data types.
-   **utils/**: A collection of helper functions used throughout the project.
-   **validation/**: Contains modules that validate both incoming (source) data and outgoing (processed) data to ensure data quality.
-   **visualization/**: Contains scripts to generate charts and other visualizations from the processed data.

The main pipeline is orchestrated by `pipeline.R`, which integrates all of these components—from data loading and transformation to aggregation, validation, and visualization that produces the final reports and charts.
